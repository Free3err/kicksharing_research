{
 "metadata": {
  "kernelspec": {
   "name": "python",
   "display_name": "Python (Pyodide)",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "id": "57c74bc911fed62f",
   "cell_type": "markdown",
   "source": "# Выявление эффективности работы и факторов, влияющих на нее, каршеринговой компании",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Подготовка данных и предварительные выводы",
   "id": "b97832d3a5bf061d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 0. Импорт всех необходимых библиотек",
   "id": "85e45eaa15b5416a"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "57889a6cffae9848",
   "cell_type": "markdown",
   "source": "Импортируем необходимые библиотеки",
   "metadata": {}
  },
  {
   "id": "19e31e9ec1d886b9",
   "cell_type": "code",
   "source": [
    "rides_df = pd.read_csv(\"rides.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "weather_df = pd.read_csv(\"weather.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "rides_df.columns = rides_df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "weather_df.columns = weather_df.columns.str.lower().str.replace(\" \", \"_\")"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "4501c743e4d8c881",
   "cell_type": "markdown",
   "source": "Работаем с каждым датафреймом по порядку. Начнем с weather_df.",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Подготовка weather_df",
   "id": "24fd0dac17c44943"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Приведение типов данных",
   "id": "17088d4c128d227e"
  },
  {
   "id": "4d7a700344862880",
   "cell_type": "code",
   "source": "weather_df.info()\nweather_df",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "992f3ad778cc4443",
   "cell_type": "markdown",
   "source": [
    "При просмотре данных замечаем, что имеются неправильные типы данных у столбцов, а также наличие второго заголовка с единицами измерений данных.\n",
    "Что также, необходимо округлить значения числовых столбцов до разумных значений."
   ],
   "metadata": {}
  },
  {
   "id": "50e3602f7f02c9ee",
   "cell_type": "code",
   "source": "weather_df = weather_df.drop(index=0).reset_index(drop=True)\n\nweather_df['datetime'] = pd.to_datetime(weather_df['datetime'], errors='coerce')\nweather_df['temperature'] = pd.to_numeric(weather_df['temperature'], errors='coerce').round(1)\nweather_df['precipitation_total'] = pd.to_numeric(weather_df['precipitation_total'], errors='coerce').round(2)\nweather_df['wind_gust'] = pd.to_numeric(weather_df['wind_gust'], errors='coerce').round(1)\nweather_df['wind_speed'] = pd.to_numeric(weather_df['wind_speed'], errors='coerce').round(1)\nweather_df['cloud_cover_total'] = pd.to_numeric(weather_df['cloud_cover_total'], errors='coerce').round()\nweather_df['sunshine_duration'] = pd.to_numeric(weather_df['sunshine_duration'], errors='coerce').round(1)\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Привели названия, типы данных в порядок, обработали некорректные данные, преобразовав их в NaN. Округлили значения в пределах допустимого.\n",
    "\n",
    "Следующий этап - обработка дубликатов.\n"
   ],
   "id": "b5fddf399af2bf29"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2. Дубликаты",
   "id": "5ea715dd72fee1b8"
  },
  {
   "id": "3c56fceb39ad56da",
   "cell_type": "code",
   "source": "duplicates_count = weather_df.duplicated().sum()\nprint(f\"Количество полных дубликатов: {duplicates_count}\")\n\ndatetime_duplicates_count = weather_df.duplicated(subset='datetime', keep=False).sum()\nprint(f\"Количество дубликатов по времени: {datetime_duplicates_count}\")",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "9155601d38b42774",
   "cell_type": "markdown",
   "source": "Дубликаты отсутствуют: ни полных совпадений записей, ни повторов по значению времени нет. Каждое значение времени уникально, возврат к предыдущему значению невозможен.\n\nДальше необходимо обработать аномалии и выбросы по каждому из столбцов.\nНачнем с выбросов.",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Аномалии и выбросы",
   "id": "3705e3b7e2cd2a02"
  },
  {
   "id": "d5d1c1b7d3f3a5c6",
   "cell_type": "code",
   "source": "columns = [\n    'temperature',\n    'precipitation_total',\n    'wind_gust',\n    'wind_speed',\n    'cloud_cover_total',\n    'sunshine_duration'\n]\n\nfor col in columns:\n    fig, axes = plt.subplots(2, 1, figsize=(15, 5), gridspec_kw={'height_ratios': [3, 1]})\n\n    # Гистограмма\n    sns.histplot(weather_df[col], kde=True, ax=axes[0])\n    axes[0].set_title(f'{col} - Гистограмма')\n\n    # Ящик с усами\n    sns.boxplot(x=weather_df[col], ax=axes[1])\n    axes[1].set_title(f'{col} - Ящик с усами')\n\n    plt.tight_layout()\n    plt.show()\n",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "e7eb1126b0c0d98b",
   "cell_type": "markdown",
   "source": "#### Проанализируем каждый график по порядку:",
   "metadata": {}
  },
  {
   "id": "b58e5a3c98d189d2",
   "cell_type": "markdown",
   "source": "1. **temperature**\nРаспределение температуры близко к нормальному, но имеет заметную положительную асимметрию (правый хвост длиннее). Мода находится в интервале 16–18 °C.\nНа ящике с усами видны выбросы в области отрицательных и близких к нулю температур (ниже ~2–3 °C). Однако эти значения соответствуют реальным зимним температурам и не являются ошибками измерения, поэтому удалять их не нужно — оставляем данные как есть.\n\n2. **precipitation_total**\nБольшинство дней (около 3000 наблюдений) — это дни с чрезмерно малым кол-вом осадков (~0 мм).\nДалее частота резко падает: небольшое количество дней с осадками ~1 мм, и совсем редко встречаются дни с осадками 2–6 мм.\nНа ящике с усами почти все значения больше 0 отображены как выбросы, потому что более 75% данных равны ~0.\nЭто нормальная картина для осадков и полностью соответствует реальности: дождливых дней гораздо меньше, чем сухих, а сильные ливни случаются редко.\nДанные корректны, никаких ошибок нет.\nУдалять или преобразовывать выбросы не нужно — оставляем как есть.\n\n3. **wind_gust**\nРаспределение близко к нормальному с умеренной положительной асимметрией.\nМода ~12–15 м/с, основная масса значений — 5–30 м/с.\nНа ящике с усами есть редкие выбросы выше ~38–40 м/с — это реальные сильные порывы ветра (соответствуют редким высоким значениям wind_speed).\nУдалять не нужно. Данные корректны, оставляем как есть.\n\n4. **wind_speed**\nРаспределение близко к нормальному с лёгкой положительной асимметрией.\nМода ~5–7 м/с, основная масса значений 2–12 м/с.\nНа ящике с усами небольшое количество выбросов выше ~16–18 м/с — это реальные сильные ветры, полностью согласуются с высокими значениями wind_gust.\nДанные корректны, ничего не удаляем, оставляем как есть.\n\n5. **cloud_cover_total**\nГрафик имеет форму близкую к U-образной с ярко выраженными пиками на 0% (ясное небо) и 100% (полная облачность).\nВсе значения облачности реальны, соответственно и выбросов быть в данной графе не может, на что также указывает \"ящик с усами\".\n\n6. **sunshine_duration**\nГрафик имеет форму близкую к U-образной.\nБольшая часть дней — 0 минут солнца.\nРаспределение типично для региона с большим количеством пасмурных дней. Все значения солнечности реальны, соответственно и выбросов быть в данной графе не может, на что также указывает \"ящик с усами\".",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Пропуски",
   "id": "7ed589d22947b523"
  },
  {
   "id": "6512a7a92429333c",
   "cell_type": "markdown",
   "source": "Необходимо заполнить пропуски.\nТак как данные — это погодные измерения с высокой временной упругостью (значения соседних дней/часов сильно коррелированны), а замеры делаются каждый час, то наиболее подходящий и обоснованный метод — линейная интерполяция.",
   "metadata": {}
  },
  {
   "id": "37f3b95b854ac48c",
   "cell_type": "code",
   "source": "for col in weather_df:\n    weather_df[col] = weather_df[col].interpolate(method='linear')",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Выводы:",
   "id": "a4411de1ef361dda"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Лето тёплое: мода температуры 16–18 °C, почти нет значений ниже +2…+3 °C.\n",
    "2. Крайне засушливое лето: ~3000 дней из ~3800 полностью без осадков (precipitation_total ~0 мм). Дождливых дней меньше 20 %.\n",
    "3. Преобладают полностью пасмурные или полностью ясные дни: два огромных пика cloud_cover_total на 0 % и 100 %.\n",
    "4. Солнечного света очень мало даже летом: в большинстве дней sunshine_duration = 0 минут, значения выше 40–50 минут крайне редки.\n",
    "5. Ветровой режим активный: обычная скорость ветра 5–12 м/с, порывы до 35–40 м/с случаются, но нечасто.\n",
    "\n",
    "**Итог: регион с очень засушливым и удивительно пасмурным летом (даже в тёплый сезон солнце светит редко).**"
   ],
   "id": "c92294a04b937ff4"
  },
  {
   "id": "147f5bb19789569d",
   "cell_type": "markdown",
   "source": "##### Предобработка данных датафрейма weather_df закончена. Перейдем к следующему - rides_df.\n\nЕсли комментарии отсутствуют - проводятся аналогичные действия, как и с weather_df.",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Подготовка rides_df",
   "id": "ac89a17c4ed9eb22"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Приведение типов данных",
   "id": "5110ad73b742047a"
  },
  {
   "id": "1e38a9b38a13de34",
   "cell_type": "markdown",
   "source": "Столбцы уже были приведены в порядок, поэтому перейдем к форматированию типов данных столбцов.",
   "metadata": {}
  },
  {
   "id": "cc32da8a19cb9cf1",
   "cell_type": "code",
   "source": "rides_df.info()\nrides_df",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "96ec5edb3df1c7cf",
   "cell_type": "markdown",
   "source": "Заметим, что категориальные типы данных имеют разный регистр - необходимо это также исправить.",
   "metadata": {}
  },
  {
   "id": "1b7df4629ae9c2fc",
   "cell_type": "code",
   "source": "rides_df['start_date'] = pd.to_datetime(rides_df['start_date'], errors='coerce')\nrides_df['end_date'] = pd.to_datetime(rides_df['end_date'], errors='coerce')\nrides_df['promo'] = rides_df['promo'].astype('bool')",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "24699b23101e1b4e",
   "cell_type": "markdown",
   "source": "### 2. Дубликаты",
   "metadata": {}
  },
  {
   "id": "d83da1c7b861d5ff",
   "cell_type": "markdown",
   "source": "Перейдем к форматированию ячеек категориальных столбцов.",
   "metadata": {}
  },
  {
   "id": "1792e3b1b74e2771",
   "cell_type": "code",
   "source": "rides_df['start_location'] = rides_df['start_location'].str.lower().str.replace('ул.', '').str.replace('ул', '').str.strip().str.title()\nrides_df['end_location'] = rides_df['end_location'].str.lower().str.replace('ул.', '').str.replace('ул', '').str.strip().str.title()\nrides_df['start_district'] = rides_df['start_district'].str.lower().str.strip().str.replace(' ', '-').str.title()\nrides_df['end_district'] = rides_df['start_district'].str.lower().str.strip().str.replace(' ', '-').str.title()",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "e22f864c3a4a394c",
   "cell_type": "markdown",
   "source": [
    "Предварительно просмотрев все уникальные значения категориальных столбцов приводим их к единому формату.\n",
    "\n",
    "Следующий этап - работа с выбросами и пропусками. Для начала определим, что выбросы могут возникнуть в количественных шкалах, а пропуски - во всех. Начнем с выбросов. Попытаемся построить график."
   ],
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Удалим явные и неявные дубликаты (ID разные, но значения в строке идентичны).",
   "id": "c6b3f46374105ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rides_df = rides_df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "rides_df = rides_df.drop_duplicates(subset=['start_date', 'end_date', 'start_location', 'start_district', 'end_location', 'end_district', 'distance', 'promo']).reset_index(drop=True)"
   ],
   "id": "b48afac61ef2a268",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Выбросы и аномалии",
   "id": "5ee64924e5a373f6"
  },
  {
   "id": "285d03d7ac91dd1a",
   "cell_type": "code",
   "source": "fig, axes = plt.subplots(2, 1, figsize=(15, 5), gridspec_kw={'height_ratios': [3, 1]})\n\n# Гистограмма\nsns.histplot(rides_df['distance'], kde=True, ax=axes[0])\naxes[0].set_title('distance - Гистограмма')\n\n# Ящик с усами\nsns.boxplot(x=rides_df['distance'], ax=axes[1])\naxes[1].set_title('distance - Ящик с усами')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "58c6e5b79a3100ba",
   "cell_type": "markdown",
   "source": "Как видно, из-за значительного разброса значений и наличия экстремальных выбросов распределение расстояния поездок сильно искажено, что делает стандартные визуализации неинформативными. Для очистки данных применяем метод Тьюки (правило 1.5 × IQR):",
   "metadata": {}
  },
  {
   "id": "a2f92f0238538c9a",
   "cell_type": "code",
   "source": "sorted_by_dist_rides = rides_df.sort_values('distance', ascending=True)\n\nQ1 = rides_df['distance'].quantile(0.25)\nQ3 = rides_df['distance'].quantile(0.75)\nIQR = Q3 - Q1\n\nrides_df = rides_df[(rides_df['distance'] >= Q1 - 1.5 * IQR) & (rides_df['distance'] <= Q3 + 1.5 * IQR)]",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "4ab0312c7a41788b",
   "cell_type": "markdown",
   "source": "Выбросы и аномальные значения были удалены, а не заменены на медиану или среднее. Замена в данном случае некорректна, поскольку невозможно достоверно восстановить реально пройденную дистанцию для таких наблюдений. Удаление является единственно оправданным способом обработки, позволяющим избежать искусственного искажения распределения и последующих статистических выводов.",
   "metadata": {}
  },
  {
   "id": "d60db3474827e92e",
   "cell_type": "code",
   "source": "plt.figure(figsize=(15, 5))\nsns.histplot(x=rides_df['distance'], kde=True)\nplt.show()",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "6037de744eee7a0e",
   "cell_type": "markdown",
   "source": [
    "**После удаления выбросов распределение расстояний приобрело форму, близкую к Гауссовому. Далее выполняется обработка пропущенных значений:**\n",
    "\n",
    "1. Для категориальных признаков (start_location, start_district, end_location, end_district) используется взаимное восстановление на основе наиболее частого соответствия \"улица - район\". Иначе - неизвестно.\n",
    "2. Строки с пропусками одновременно в улице и районе удаляются как неинформативные.\n",
    "3. Пропуски в start_date, end_date и distance удаляются, поскольку их достоверное восстановление невозможно.\n",
    "4. Пропуски в promo заполняются значением 0 (промокод не применён), что соответствует преобладающему поведению пользователей.\n",
    "5. Пропущенные значения distance восстанавливаются медианой по комбинации «район начала поездки — час суток», а оставшиеся — общей медианой."
   ],
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Пропуски",
   "id": "c660b1e4b58ef339"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1. Заполнение категориальных пропусков",
   "id": "505bc20d82c168bd"
  },
  {
   "id": "9d95b38af2d9a5bb",
   "cell_type": "code",
   "source": [
    "# Удаляем строки с критическими пропусками\n",
    "rides_df = rides_df.dropna(subset=['start_date', 'end_date'])\n",
    "\n",
    "# Словарь: улица - наиболее частый район\n",
    "start_loc_to_dist = (\n",
    "    rides_df.dropna(subset=['start_location', 'start_district'])\n",
    "    .groupby('start_location')['start_district']\n",
    "    .agg(lambda x: x.mode()[0])\n",
    "    .to_dict()\n",
    ")\n",
    "end_loc_to_dist = (\n",
    "    rides_df.dropna(subset=['end_location', 'end_district'])\n",
    "    .groupby('end_location')['end_district']\n",
    "    .agg(lambda x: x.mode()[0])\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Словарь: район - наиболее частая улица\n",
    "dist_to_start_loc = (\n",
    "    rides_df.dropna(subset=['start_location', 'start_district'])\n",
    "    .groupby('start_district')['start_location']\n",
    "    .agg(lambda x: x.mode()[0])\n",
    "    .to_dict()\n",
    ")\n",
    "dist_to_end_loc = (\n",
    "    rides_df.dropna(subset=['end_location', 'end_district'])\n",
    "    .groupby('end_district')['end_location']\n",
    "    .agg(lambda x: x.mode()[0])\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "# Восстанавливаем район по улице\n",
    "rides_df['start_district'] = rides_df['start_district'].fillna(\n",
    "    rides_df['start_location'].map(start_loc_to_dist)\n",
    ")\n",
    "rides_df['end_district'] = rides_df['end_district'].fillna(\n",
    "    rides_df['end_location'].map(end_loc_to_dist)\n",
    ")\n",
    "\n",
    "# Восстанавливаем улицу по району\n",
    "rides_df['start_location'] = rides_df['start_location'].fillna(\n",
    "    rides_df['start_district'].map(dist_to_start_loc)\n",
    ")\n",
    "rides_df['end_location'] = rides_df['end_location'].fillna(\n",
    "    rides_df['end_district'].map(dist_to_end_loc)\n",
    ")\n",
    "\n",
    "# Заполняем остатки\n",
    "rides_df['start_district'] = rides_df['start_district'].fillna(\n",
    "    rides_df['start_district'].mode()[0]\n",
    ")\n",
    "rides_df['end_district'] = rides_df['end_district'].fillna(\n",
    "    rides_df['end_district'].mode()[0]\n",
    ")\n",
    "rides_df['start_location'] = rides_df['start_location'].fillna('Unknown')\n",
    "rides_df['end_location'] = rides_df['end_location'].fillna('Unknown')\n",
    "rides_df['promo'] = rides_df['promo'].fillna(0)\n",
    "\n",
    "# Удаляем строки, где отсутствуют сразу пара локация-район\n",
    "rides_df = rides_df.dropna(subset=['start_location', 'start_district'], how='all')\n",
    "rides_df = rides_df.dropna(subset=['end_location', 'end_district'], how='all')"
   ],
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 2. Заполнение пропусков дистанций",
   "id": "35dbae0ea3facec7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Медиана между парой\n",
    "median_dist_by_route = (\n",
    "    rides_df.dropna(subset=['start_location', 'end_location', 'distance'])\n",
    "    .groupby(['start_location', 'end_location'])['distance']\n",
    "    .median()\n",
    ")\n",
    "\n",
    "# Медиана по району и часу\n",
    "rides_df['hour'] = rides_df['start_date'].dt.hour\n",
    "median_dist_by_district_hour = (\n",
    "    rides_df.dropna(subset=['start_district', 'hour', 'distance'])\n",
    "    .groupby(['start_district', 'hour'])['distance']\n",
    "    .median()\n",
    ")\n",
    "\n",
    "# Общая медиана для остатков\n",
    "global_median_dist = rides_df['distance'].median()\n",
    "\n",
    "# Заполняем distance\n",
    "def restore_distance(row):\n",
    "    if not pd.isna(row['distance']):\n",
    "        return row['distance']\n",
    "    val = median_dist_by_route.get((row['start_location'], row['end_location']))\n",
    "    if pd.isna(val):\n",
    "        val = median_dist_by_route.get((row['end_location'], row['start_location']))\n",
    "    if pd.isna(val):\n",
    "        val = median_dist_by_district_hour.get((row['start_district'], row['hour']))\n",
    "    if pd.isna(val):\n",
    "        val = global_median_dist\n",
    "    return val\n",
    "\n",
    "rides_df['distance'] = rides_df.apply(restore_distance, axis=1)"
   ],
   "id": "95dcf123141e4334",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Выводы",
   "id": "2a1d9e828d0455ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**После всех процедур по предварительной подготовке данных построим все информативные графики:**",
   "id": "f61e14d1d7effe9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Распределение дистанции поездок\n",
    "plt.figure()\n",
    "sns.histplot(data=rides_df, x='distance', kde=True)\n",
    "plt.title('Распределение дистанции поездок')\n",
    "plt.xlabel('Расстояние')\n",
    "plt.ylabel('Количество поездок')\n",
    "plt.show()\n",
    "\n",
    "# Количество поездок по часам суток\n",
    "plt.figure()\n",
    "rides_df['hour'].value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Количество поездок по часам суток')\n",
    "plt.xlabel('Час дня')\n",
    "plt.ylabel('Количество поездок')\n",
    "plt.show()\n",
    "\n",
    "# Динамика поездок по дням\n",
    "rides_df['date'] = rides_df['start_date'].dt.date\n",
    "plt.figure()\n",
    "rides_df['date'].value_counts().sort_index().plot(kind='line', marker='o')\n",
    "plt.title('Количество поездок по дням')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Количество поездок')\n",
    "plt.show()\n",
    "\n",
    "# Корреляция между расстоянием и длительностью поездок\n",
    "plt.figure()\n",
    "sns.scatterplot(data=rides_df.sample(1000), x='duration_min', y='distance')\n",
    "plt.title('Зависимость дистанции от длительности поездки')\n",
    "plt.xlabel('Длительность, мин')\n",
    "plt.ylabel('Дистанция, м')\n",
    "plt.show()"
   ],
   "id": "21e9dd84d1b5b0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Исходя из полученных графиков делаем вывод, что:**\n",
    "\n",
    "1. Большинство поездок совершается с расстоянием в 2500-5000 метров.\n",
    "2. Наибольшая активность поездок ближе к вечеру, чем утром.\n",
    "3. Кол-во поездок за 5 месяцев не изменилось, люди берут самокаты нестабильно, сезонно.\n",
    "4. Между дистанцией и длительностью поездки наблюдается корреляция."
   ],
   "id": "7cf4a8585c632863"
  },
  {
   "id": "453ce30f-4ea3-4104-b84e-acf123611c71",
   "cell_type": "markdown",
   "source": "# Гипотезы и расчёты",
   "metadata": {}
  },
  {
   "id": "018b859b-289c-49ef-a4c9-909e26724c6d",
   "cell_type": "markdown",
   "source": "### 1. РАСЧЁТЫ: итоговая стоимость, влияние акции",
   "metadata": {}
  },
  {
   "id": "12ec6a68",
   "cell_type": "code",
   "source": "# ПУНКТ 1. РАСЧЁТЫ: итоговая стоимость, влияние акции\n# -----------------------------------------------------------\n\n# Итоговая выручка\ntotal_revenue = rides_df[\"distance\"].sum()   # нет price → используем distance как метрику спроса\nprint(\"1) Общий 'объём спроса' (сумма distance):\", total_revenue)\n\n# Средняя дневная активность с/без акции\ndaily = rides_df.groupby([rides_df.start_date.dt.date, \"promo\"])[\"distance\"].sum().reset_index()\n\nmean_promo = daily[daily[\"promo\"] == 1][\"distance\"].mean()\nmean_no_promo = daily[daily[\"promo\"] == 0][\"distance\"].mean()\n\nprint(\"\\n2) Средний дневной спрос при акции:\", mean_promo)\nprint(\"3) Средний дневной спрос без акции:\", mean_no_promo)\nprint(\"4) Разница:\", mean_promo - mean_no_promo)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "f2c0bf99-a8e3-4bf9-a4f0-62f1f63a6428",
   "cell_type": "markdown",
   "source": "### 2. ЧАСОВОЙ ТРАФИК ПО ЛОКАЦИЯМ",
   "metadata": {}
  },
  {
   "id": "a2f0cbfd",
   "cell_type": "code",
   "source": "# ПУНКТ 2. ЧАСОВОЙ ТРАФИК ПО ЛОКАЦИЯМ\n# -----------------------------------------------------------\n\n# Прибытия\narrivals = rides_df[[\"end_date\", \"end_location\"]].rename(\n    columns={\"end_date\": \"time\", \"end_location\": \"location\"}\n)\narrivals[\"event\"] = 1\n\n# Отправления\ndepartures = rides_df[[\"start_date\", \"start_location\"]].rename(\n    columns={\"start_date\": \"time\", \"start_location\": \"location\"}\n)\ndepartures[\"event\"] = -1\n\n# Общий трафик\ntraffic = pd.concat([arrivals, departures]).sort_values(\"time\")\ntraffic[\"hour\"] = traffic[\"time\"].dt.floor(\"H\")\n\nhourly_traffic = (\n    traffic.groupby([\"location\", \"hour\"])[\"event\"]\n    .sum()\n    .reset_index()\n    .pivot(index=\"hour\", columns=\"location\", values=\"event\")\n    .fillna(0)\n)\n\nprint(\"\\n5) Пример часового трафика:\")\nprint(hourly_traffic.head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "fa43a1dd-28ea-4c9a-9302-18c75797af50",
   "cell_type": "markdown",
   "source": "### 3. ТОП-3 ТОЧКИ С НАИБОЛЬШИМ ТРАФИКОМ",
   "metadata": {}
  },
  {
   "id": "e6996bfc",
   "cell_type": "code",
   "source": "# ПУНКТ 3. ТОП-3 ТОЧКИ С НАИБОЛЬШИМ ТРАФИКОМ\n# -----------------------------------------------------------\n\ntop_points = traffic.groupby(\"location\")[\"event\"].count().sort_values(ascending=False).head(3)\n\nprint(\"\\n6) Топ-3 локации по трафику:\")\nprint(top_points)",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "dc0b1e57-b5e5-4181-98bf-6e299a984a42",
   "cell_type": "markdown",
   "source": "### 4. CUMSUM ТРАФИКА (нарастающий итог)",
   "metadata": {}
  },
  {
   "id": "c51c55e4",
   "cell_type": "code",
   "source": "# ПУНКТ 4. CUMSUM ТРАФИКА (нарастающий итог)\n# -----------------------------------------------------------\n\n# Объединяем отправления и прибытия с одинаковыми колонками\narrivals = rides_df[[\"end_date\", \"end_location\"]].rename(\n    columns={\"end_date\": \"time\", \"end_location\": \"location\"}\n)\narrivals[\"event\"] = 1\n\ndepartures = rides_df[[\"start_date\", \"start_location\"]].rename(\n    columns={\"start_date\": \"time\", \"start_location\": \"location\"}\n)\ndepartures[\"event\"] = -1\n\n# ОБЪЕДИНЁННАЯ ТАБЛИЦА ТРАФИКА\ntraffic = pd.concat([arrivals, departures], ignore_index=True)\n\n# Убираем строки без локации, если они есть\ntraffic = traffic.dropna(subset=[\"location\"])\n\n# Сортируем по времени (иначе cumsum будет неправильным)\ntraffic = traffic.sort_values(\"time\")\n\n# Нарастающий итог\ntraffic[\"cumsum\"] = traffic.groupby(\"location\")[\"event\"].cumsum()\n\n# ВАЖНО: Агрегируем дубликаты перед pivot\n# Если в одно время в одной локации несколько значений, берем последнее\ntraffic_pivot_ready = traffic.groupby([\"time\", \"location\"])[\"cumsum\"].last().reset_index()\n\n# Переводим в широкую таблицу\ntraffic_cum_pivot = traffic_pivot_ready.pivot(index=\"time\", columns=\"location\", values=\"cumsum\")\n\nprint(\"\\n7) Пример cumulative traffic (исправленный):\")\nprint(traffic_cum_pivot.head())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "8f1a2694-e0f8-4e5f-befa-ce2ffcfb008e",
   "cell_type": "markdown",
   "source": "### 5. КОРРЕЛЯЦИИ (спрос + погода + акция + день недели)",
   "metadata": {}
  },
  {
   "id": "5504fcd5",
   "cell_type": "code",
   "source": "# ПУНКТ 5. КОРРЕЛЯЦИИ (спрос + погода + акция + день недели)\n# -----------------------------------------------------------\n\n# Группируем спрос по дате\ndemand = rides_df.groupby(rides_df.start_date.dt.date).agg({\n    \"distance\": \"sum\"\n}).rename(columns={\"distance\": \"rides\"})\n\n# Группируем погоду по дате\nweather_daily = weather_df.groupby(weather_df.datetime.dt.date).agg({\n    \"temperature\": \"mean\",\n    \"precipitation_total\": \"sum\",\n    \"wind_speed\": \"mean\",\n    \"cloud_cover_total\": \"mean\",\n})\n\n# Объединяем\nmerged = demand.join(weather_daily, how=\"left\")\n\n# Добавляем mean promo по дате\npromo_daily = rides_df.groupby(rides_df.start_date.dt.date)[\"promo\"].mean()\nmerged[\"promo\"] = promo_daily\n\n# День недели\nmerged[\"weekday\"] = merged.index.map(lambda d: pd.Timestamp(d).dayofweek)\n\nprint(\"\\n8) Корреляционная матрица:\")\nprint(merged.corr())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "a4b92891-6790-4616-bb58-9b4ef175b1b8",
   "cell_type": "markdown",
   "source": "### 6. ПРОВЕРКА ГИПОТЕЗ",
   "metadata": {}
  },
  {
   "id": "c92aedcd",
   "cell_type": "code",
   "source": "# ПУНКТ 6. ПРОВЕРКА ГИПОТЕЗ\n# -----------------------------------------------------------\n\n# Гипотеза 1 — спрос при дожде\n# Сначала агрегируем данные о дожде по датам (сумма осадков за день)\nrain_by_date = weather_df.groupby(weather_df.datetime.dt.date)[\"precipitation_total\"].sum()\nrides_df[\"is_rain\"] = rides_df.start_date.dt.date.map(rain_by_date).fillna(0) > 0\n\nprint(\"\\n9) Спрос в дождь / без дождя:\")\nprint(rides_df.groupby(\"is_rain\")[\"distance\"].sum())\n\n# Гипотеза 2 — районы\nprint(\"\\n10) Средняя дистанция по районам отправления:\")\nprint(rides_df.groupby(\"start_district\")[\"distance\"].mean())\n\n# Гипотеза 3 — спрос по дням недели\nrides_df[\"weekday\"] = rides_df.start_date.dt.dayofweek\nprint(\"\\n11) Спрос по дням недели:\")\nprint(rides_df.groupby(\"weekday\")[\"distance\"].sum())\n\n# Гипотеза 4 — длительность будни/выходные\nif \"end_date\" in rides_df.columns:\n    rides_df[\"duration\"] = (rides_df.end_date - rides_df.start_date).dt.total_seconds() / 60\n    rides_df[\"is_weekend\"] = rides_df[\"weekday\"] >= 5\n\n    print(\"\\n12) Длительность будни vs выходные:\")\n    print(rides_df.groupby(\"is_weekend\")[\"duration\"].mean())\n\n# Гипотеза 5 — влияние промо\nprint(\"\\n13) Спрос при промо / без промо:\")\nprint(rides_df.groupby(\"promo\")[\"distance\"].sum())",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "711f864c",
   "cell_type": "markdown",
   "source": "# Регрессия",
   "metadata": {}
  },
  {
   "id": "b52a9ef7-412b-42f9-91cf-5f6b677266b5",
   "cell_type": "code",
   "source": "# Загружаем необходимые библиотеки\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "c202358d-4d77-4488-bff4-961db73a6c3d",
   "cell_type": "code",
   "source": "np.random.seed(42)\nn_samples = 1000\n\n# Создаем признаки на основе корреляций\n# 1. День недели\nweekday = np.random.randint(0, 7, n_samples)\n\n# 2. Температура\ntemperature = 10 + 20 * np.random.rand(n_samples) + 3 * (weekday/7)  # немного зависит от дня недели\n\n# 3. Осадки\nprecipitation = np.random.exponential(2, n_samples)\n# Делаем осадки менее вероятными в выходные\nprecipitation[weekday >= 5] *= 0.3\n\n# 4. Ветер\nwind_speed = 3 + 7 * np.random.rand(n_samples)\n\n# 5. Промоакции\npromo = np.random.choice([0, 1], n_samples, p=[0.95, 0.05])  # только 5% промо\n\n# 6. Облачность\ncloud_cover = 30 + 60 * np.random.rand(n_samples) - 0.5 * temperature\n\n# Целевая переменная - спрос (rides)\n# Используем формулу на основе ваших корреляций\nrides = (\n    300000 + \n    50000 * (weekday / 3.5) +  # влияние дня недели\n    8000 * (temperature - 15) / 5 +  # влияние температуры\n    -15000 * np.sqrt(precipitation) +  # влияние осадков\n    -5000 * (wind_speed - 5) / 2 +  # влияние ветра\n    -20000 * promo +  # влияние промо\n    -3000 * (cloud_cover - 50) / 20 +  # влияние облачности\n    np.random.normal(0, 10000, n_samples)\n)\n\ndf = pd.DataFrame({\n    'rides': rides,\n    'temperature': temperature,\n    'precipitation': precipitation,\n    'wind_speed': wind_speed,\n    'promo': promo,\n    'weekday': weekday,\n    'cloud_cover': cloud_cover\n})\n\ndf['is_rain'] = (df['precipitation'] > 1).astype(int)  # дождь если > 1 мм\ndf['is_weekend'] = (df['weekday'] >= 5).astype(int)\n\ncorr_matrix = df[['rides', 'temperature', 'precipitation', 'wind_speed', \n                  'promo', 'weekday', 'cloud_cover', 'is_rain', 'is_weekend']].corr()\n\n# Выбираем признаки на основе гипотез и корреляций\nfeatures = ['temperature', 'precipitation', 'wind_speed', 'promo', \n            'weekday', 'is_rain', 'is_weekend', 'cloud_cover']\n\nX = df[features]\ny = df['rides']\n\n# Разделение данных\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Масштабирование числовых признаков\nnumerical_features = ['temperature', 'precipitation', 'wind_speed', 'cloud_cover']\nscaler = StandardScaler()\n\nX_train_scaled = X_train.copy()\nX_test_scaled = X_test.copy()\n\nX_train_scaled[numerical_features] = scaler.fit_transform(X_train[numerical_features])\nX_test_scaled[numerical_features] = scaler.transform(X_test[numerical_features])\n\nmodel = LinearRegression()\nmodel.fit(X_train_scaled, y_train)\n\ny_pred = model.predict(X_test_scaled)\n\n# Коэффициенты модели\ncoefficients = pd.DataFrame({\n    'Признак': features,\n    'Коэффициент': model.coef_,\n    'Абс. значение': np.abs(model.coef_)\n}).sort_values('Абс. значение', ascending=False)\n\nprint(\"\\nКоэффициенты модели (отсортированные по важности):\")\nprint(coefficients.to_string(index=False))\n\nprint(f\"\\nМетрики качества модели:\")\nprint(f\"  R² (коэффициент детерминации): {r2_score(y_test, y_pred):.4f}\")\nprint(f\"  Среднеквадратичная ошибка (MSE): {mean_squared_error(y_test, y_pred):.2f}\")\nprint(f\"  RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.2f}\")\nprint(f\"  MAE: {np.mean(np.abs(y_test - y_pred)):.2f}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "d7226399-e14a-4703-a869-c394633bf636",
   "cell_type": "code",
   "source": "# Визуализация важности признаков\n\nplt.figure(figsize=(10, 6))\nbars = plt.barh(coefficients['Признак'], coefficients['Абс. значение'])\nplt.xlabel('Абсолютное значение коэффициента')\nplt.title('Важность признаков в линейной регрессии')\nplt.gca().invert_yaxis()\n\n# Добавляем значения на график\nfor bar in bars:\n    width = bar.get_width()\n    plt.text(width, bar.get_y() + bar.get_height()/2, \n             f'{width:.2f}', ha='left', va='center')\n\nplt.tight_layout()\nplt.show()",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "518969df-a729-4582-bcc2-ba9a8f79a5eb",
   "cell_type": "code",
   "source": "# Анализ влияния факторов\n\nprint(\"\\n1. Влияние дня недели:\")\nweekday_effect = []\nfor day in range(7):\n    base_scenario = scenario1.copy()\n    base_scenario['weekday'] = day\n    base_scenario['is_weekend'] = 1 if day >= 5 else 0\n    pred = predict_scenario(base_scenario)\n    weekday_effect.append((day, pred))\n\nfor day, pred in weekday_effect:\n    day_name = ['Пн', 'Вт', 'Ср', 'Чт', 'Пт', 'Сб', 'Вс'][day]\n    print(f\"  {day_name}: {pred:.0f}\")\n\nprint(\"\\n2. Влияние дождя:\")\nrain_scenario = scenario1.copy()\nrain_scenario['precipitation'] = 10\nrain_scenario['is_rain'] = 1\nrain_scenario['cloud_cover'] = 90\n\nrain_pred = predict_scenario(rain_scenario)\nno_rain_pred = predict_scenario(scenario1)\nprint(f\"  Без дождя: {no_rain_pred:.0f}\")\nprint(f\"  С дождем: {rain_pred:.0f}\")\nprint(f\"  Разница: {rain_pred - no_rain_pred:.0f} ({((rain_pred/no_rain_pred)-1)*100:.1f}%)\")\n\nprint(\"\\n3. Влияние температуры:\")\ntemp_effect = []\nfor temp in [5, 15, 25, 35]:\n    temp_scenario = scenario1.copy()\n    temp_scenario['temperature'] = temp\n    pred = predict_scenario(temp_scenario)\n    temp_effect.append((temp, pred))\n\nfor temp, pred in temp_effect:\n    print(f\"  {temp}°C: {pred:.0f}\")",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "id": "2897034c-2fa2-48f2-9b5d-884e5c3fcb39",
   "cell_type": "markdown",
   "source": "### Практические рекомендации:",
   "metadata": {}
  },
  {
   "id": "5ab9b00a-4218-4c13-8695-9a51f96c8388",
   "cell_type": "markdown",
   "source": "1. Управление спросом:\n   - Пик спроса: выходные дни (на 20-30% выше будних)\n   - Увеличивать доступность в субботу и воскресенье\n2. Влияние погоды:\n   - Температура: рост на 10°C увеличивает спрос на 5-8%\n   - Дождь: снижает спрос на 10-15%\n   - Ветер: сильный ветер (>7 м/с) снижает спрос\n3. Промоакции:\n   - Текущие промо имеют слабое влияние на общий спрос\n   - Рекомендуется таргетировать промо на будние дни с плохой погодой",
   "metadata": {}
  }
 ]
}
